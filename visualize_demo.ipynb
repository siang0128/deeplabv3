{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "import deeplab\n",
    "from pascal import VOCSegmentation\n",
    "from cityscapes import Cityscapes\n",
    "from utils import AverageMeter, inter_and_union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation_with_mask(folder):\n",
    "    _train = True #training mode\n",
    "    _exp = 'bn_lr7e-3' #name of experiment\n",
    "    _gpu = 0 #test time gpu device id\n",
    "    _backbone = 'resnet101' \n",
    "    _dataset = 'pascal' #model: pascal or cityscapes\n",
    "    _groups = None #num of groups for group normalization\n",
    "    _epochs = 50 #num of training epochs\n",
    "    _batch_size = 8 #batch size\n",
    "    _base_lr = 0.007 #base learning rate\n",
    "    _last_mult = 1.0 #learning rate multiplier for last layers\n",
    "    _scratch = False #train from scratch\n",
    "    _freeze_bn = False #freeze batch normalization parameters\n",
    "    _weight_std = False #weight standardization\n",
    "    _beta = False #resnet101 beta\n",
    "    _crop_size = 513 #image crop size\n",
    "    _resume = None #path to checkpoint to resume from\n",
    "    _workers = 4 #number of data loading workers\n",
    "    if not os.path.exists(folder):\n",
    "        print('file \\\"{}\\\" doesn\\'t exist.'.format(folder))\n",
    "        return\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model_fname = 'data/deeplab_{0}_{1}_v3_{2}_epoch%d.pth'.format(_backbone, _dataset, _exp)\n",
    "    dataset = VOCSegmentation('data/VOCdevkit', train=_train, crop_size=_crop_size)\n",
    "    model = getattr(deeplab, 'resnet101')(\n",
    "                pretrained=(not _scratch),\n",
    "                num_classes=len(dataset.CLASSES),\n",
    "                num_groups=_groups,\n",
    "                weight_std=_weight_std,\n",
    "                beta=_beta)\n",
    "    model = nn.DataParallel(model)\n",
    "    torch.cuda.set_device(_gpu)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    checkpoint = torch.load(model_fname % _epochs)\n",
    "    state_dict =checkpoint['state_dict']\n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if 'module' not in k:\n",
    "            k = 'module.'+k\n",
    "        else:\n",
    "            k = k.replace('features.module.', 'module.features.')\n",
    "        new_state_dict[k]=v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    cmap = loadmat('data/pascal_seg_colormap.mat')['colormap']\n",
    "    cmap = (cmap * 255).astype(np.uint8).flatten().tolist()\n",
    "    ###load vedio\n",
    "    pics = os.listdir(folder)\n",
    "    pics.sort()\n",
    "    for i in range(len(pics)):\n",
    "        ###segmentation\n",
    "        img_path = './'+folder+'/'+pics[i]\n",
    "        #test_img = Image.open(img_path).convert(\"RGB\").resize((513,513))\n",
    "        test_img = Image.open(img_path).convert(\"RGB\")\n",
    "        test_img = np.asarray(test_img)\n",
    "    \n",
    "        '''image_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        test_in = image_transforms(test_img)\n",
    "        test_in = Variable(test_in.cuda())\n",
    "        print(test_in.shape)\n",
    "        print('00000')\n",
    "        test_out = model(test_in.unsqueeze(0))\n",
    "        print('11111')\n",
    "        _, test_pred = torch.max(test_out, 1)\n",
    "        test_pred = test_pred.data.cpu().numpy().squeeze().astype(np.uint8)\n",
    "        test_mask_pred = Image.fromarray(test_pred)\n",
    "        test_mask_pred.putpalette(cmap)\n",
    "        test_img = Image.fromarray(test_img, 'RGB')\n",
    "        img_add = cv2.addWeighted(np.asarray(test_img), 0.3, np.asarray(test_mask_pred.convert('RGB')), 0.7, 0)'''\n",
    "        display(test_img)\n",
    "        time.sleep(1)\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    folder = 'v1'\n",
    "    try:\n",
    "        visualize_segmentation_with_mask(folder)\n",
    "    except KeyboardInterrupt:\n",
    "        print('done!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
